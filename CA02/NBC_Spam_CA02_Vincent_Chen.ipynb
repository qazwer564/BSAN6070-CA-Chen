{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NBC_Spam_CA02_Vincent_Chen",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M22CFRwZuVTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import necessray packages\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV66ORk01YdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30b6d0c5-e265-406d-b15b-676141a305fe"
      },
      "source": [
        "#import google drive to import data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNsuG-XS1qD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining the function to draw most common words from training data\n",
        "def make_Dictionary(root_dir):\n",
        "  all_words = [] #set up an empty list\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] #extracting all files in folder\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words\n",
        "  dictionary = Counter(all_words) #collecting all the texts in one file and count them\n",
        "  list_to_remove = list(dictionary) #make the dictionary a list\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item] #get rid of any items with non-alphabets\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item] #get rid of items that are single letters\n",
        "  dictionary = dictionary.most_common(3000) #get words with highest frequencies\n",
        "  return dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDgoNGUT2y6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_1='/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/Data/train-mails'\n",
        "dictionary=make_Dictionary(train_1) #test dictionary with the training folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrBLE8ySTiTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)] \n",
        "  #extracting all files links from the folder in 'files'\n",
        "  features_matrix = np.zeros((len(files),3000)) #create a matrix of 3000*len(files), all zeros\n",
        "  train_labels = np.zeros(len(files)) #create a numpy array of zeros with len(files)\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in files:\n",
        "    with open(fil) as fi:\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2:\n",
        "          words = line.split() #split out words on the third line\n",
        "          for word in words:\n",
        "            wordID = 0 #ignore all words by assigning 0 first\n",
        "            for i, d in enumerate(dictionary):\n",
        "              if d[0] == word:\n",
        "                wordID = i #assign the wordID with its order in dictionary when it comes out \n",
        "                features_matrix[docID,wordID] = words.count(word) \n",
        "                #fill the count of that word in the matrix in [docID,wordID]\n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/') #split file with '/'\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1] #pick the last word from file link\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        train_labels[docID] = 1; #mark this file as spam in training_label\n",
        "        count = count + 1 #count the spmsg files\n",
        "      docID = docID + 1 #change docID bofore moving to the next file \n",
        "  return features_matrix, train_labels\n",
        "  #feature_matrix rows stand for file number, columns stand for 3000 words\n",
        "  #train_lavels are final results if a list of these files are spams, seperately"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0saUSKLji5QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/Data/train-mails'\n",
        "TEST_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/Data/test-mails'\n",
        "dictionary = make_Dictionary(TRAIN_DIR) # using functions mentioned above.\n",
        "features_matrix, labels = extract_features(TRAIN_DIR)\n",
        "test_feature_matrix, test_labels = extract_features(TEST_DIR)\n",
        "\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "#train model\n",
        "model.fit(features_matrix, labels)\n",
        "#predict\n",
        "predicted_labels = model.predict(test_feature_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN1HUkqNn9CP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb01e8e0-96aa-4e66-c1b4-0d04bea00239"
      },
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(test_labels, predicted_labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9615384615384616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}